<!DOCTYPE html>
<html lang="en">
  <head>
    <br>
    <!-- Basic Page Needs
         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <meta charset="utf-8">
    <title>Deformation-Aware Retrieval</title>
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Mobile Specific Metas
         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- FONT
         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link href="https://fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

    <!-- CSS
         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link rel="stylesheet" href="css/normalize.css">
    <link rel="stylesheet" href="css/skeleton.css">
    <link rel="stylesheet" href="css/footable.standalone.min.css">

    <!-- Favicon
         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <link rel="icon" type="image/png" href="images/favicon.png">

    <!-- Google icon -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">

    <!-- Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                               m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-86869673-1', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- Hover effect: https://codepen.io/nxworld/pen/ZYNOBZ -->
    <style>
      img {
          display: block;
      }

      .column-50 {
          float: left;
          width: 50%;
      }
      .row-50:after {
          content: "";
          display: table;
          clear: both;
      }

      .floating-teaser {
          float: left;
          width: 30%;
          text-align: center;
          padding: 15px;
      }
      .venue strong {
          color: #99324b;
      }

      .benchmark {
          width: 100%;
          max-width: 960px;
          overflow: scroll;
          overflow-y: hidden;
      }

    </style>
  </head>
  <body>

    <!-- Primary Page Layout
         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
    <div class="container">
      <h4 style="text-align:center">Deformation-Aware 3D Model Embedding and Retrieval</h4>
      <p align="center", style="margin-bottom:12px;">
        <a class="simple" href="https://mikacuy.github.io/">Mikaela Angelina Uy</a><sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a class="simple" href="http://cs.stanford.edu/~jingweih/">Jingwei Huang</a><sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a class="simple" href="https://mhsung.github.io">Minhyuk Sung</a><sup>2</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a class="simple" href="http://tbirdal.me/">Tolga Birdal</a><sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a class="simple" href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a><sup>1</sup>
      </p>

      <p align="center" style="margin-bottom:20px;">
        <sup>1</sup>Stanford University
        <span style="display:inline-block; width: 32px"></span>
        <sup>2</sup>Adobe Research <br>
      </p>

      <div class="venue">
        <p align="center"> European Conference on Computer Vision (ECCV), 2020 </p>
      </div>

      <figure>
        <img src="images/intro_image.png" style="width:100%"></img>
        <!-- <br> -->
      </figure>
      <div class="caption">
        <b>Deformation-Aware Embedding Space:</b> This figure shows an overview of 1) the design of our deformation-aware embedding space using source-dependent egocentric distance fields, 2) siamese network architecture, and 3) formulation of the asymmetric embedding distance.
      </div>

      <br><br>

      <div id="teaser" class="container" style="width:100%; margin:0; padding:0">
        <h5>Abstract</h5>
        <p align="justify">
          We introduce a new problem of <b><i>retrieving</b></i> 3D models that are <b><i>deformable</b></i> to a given query shape and present a novel deep <b><i>deformation-aware</b></i> embedding to solve this retrieval task. 3D model retrieval is a fundamental operation for recovering a clean and complete 3D model from a noisy and partial 3D scan. However, given a finite collection of 3D shapes, even the closest model to a query may not be satisfactory. This motivates us to apply 3D model deformation techniques to adapt the retrieved model so as to better fit the query. Yet, certain restrictions are enforced in most 3D deformation techniques to preserve important features of the original model that prevent a perfect fitting of the deformed model to the query. This gap between the deformed model and the query induces asymmetric relationships among the models, which cannot be handled by typical metric learning techniques. Thus, to retrieve the best models for fitting, we propose a novel deep embedding approach that learns the <b><i>asymmetric</b></i> relationships by leveraging location-dependent egocentric distance fields. We also propose two strategies for training the embedding network. We demonstrate that both of these approaches outperform other baselines in our experiments with both synthetic and real data.
          <br>
          <br>
        </p>
      </div>

      <div id="teaser" class="container" style="width:100%; margin:0; padding:0">
        <h5>Video</h5>
        <p>Long 10-min Presentation</p>
      <center>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/u_8DJ06SQdw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
      </center>
      <br>
      <p>Short 1-min Summary</p>
      <center>
      <iframe width="560" height="315" src="https://www.youtube.com/embed/O0FAOx-npc8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
      </center>      
      </div>


    <div class="section">
        <h5>Materials</h5>
        <div class="container" style="width:95%">
          <!-- Icon row -->
          <div class="row">
            <div class="two columns">
              <a href="https://arxiv.org/pdf/2004.01228.pdf"><img style="border: 1px solid #ddd; border-radius: 4px; padding: 2px; width: 108px;" src="images/screenshot_main.png"></a>
            </div>
            <div class="two columns">
              <a href="assets/slides.pdf"><img style="border: 1px solid #ddd; border-radius: 4px; padding: 2px; width: 108px;" src="images/screenshot_slides.png"></a>
            </div>
          </div>
          <!-- Link row -->
          <div class="row">
            <div class="two columns">
              <a href="https://arxiv.org/pdf/2004.01228.pdf">Paper</a>
            </div>
            <div class="two columns">
              <a href="assets/slides.pdf">Slides</a>
            </div>
          </div>

          <div class="row">
              <br>
              <a href="https://github.com/mikacuy/deformation_aware_embedding">Code</a>
              <!-- <p>Code to be released soon!</p> -->
          </div>

        </div>
      </div>

  <br>

  <div id="teaser" class="container" style="width:100%; margin:0; padding:0">
    <h5>Qualitative Results</h5>
    <center>
      <img src="images/shapenet_quali_fixed-crop.png" style="width:90%"></img>
        <div class="caption" >
          <p align="justify">
            Visualization of retrieval followed by deformation on ShapeNet. Our network is able to retrieve models
            that better fit after deformation despite having large geometric distances initially. Notice the big back part of the retrieved chair and the thick seat of the retrieved sofa, attributes that are not identical to the query. Yet, these parts properly fit the target after deformation. Our network is also able to retrieve a sofa with legs and a car with a trunk that are present in the desired targets. Moreover, our deformation-aware retrieval & deformation approach also allows us to preserve fine-details of the source model post-deformation as shown in the zoomed in regions.
          </p>
        </div>
        <br>

      <img src="images/scan2cad_fixed_compressed.png" style="width:90%"></img>
        <div class="caption" >
          <p align="justify">
            (Top row and bottom left) Qualitative results of Scan-to-CAD. (Bottom right) Quantitative Results: We compare different retrieval methods on the Scan2CAD dataset. The left chart shows the mean fitting errors and the right chart shows the number of best candidates retrieved by different methods. Ours-Reg achieves the minimum overall fitting errors and the maximum number of best retrievals among all categories compared with other methods. 
          </p>
        </div>
        <br>

      <img src="images/image2cad3_compressed.png" style="width:90%"></img>
        <div class="caption" >
          <p align="justify">
            Qualitative results to show the feasibility of our approach for the Image-toCAD application. We show one of three input viewpoints used by Pixel2Mesh++ to produce their coarse mesh. We use this to retrieve a CAD model, which is then
            deformed to fit the coarse mesh. Rigidity constraints ensure the quality of our output
            as shown. 
          </p>
        </div>
        <br>

    </center>
  </div>

		<!-- -->
	<div class="section">
          <h5>Citation</h5> 
  <pre style="margin:0"><code>@inproceedings{uy-deformawareretrieval-eccv20,
      title = {Deformation-Aware 3D Model Embedding and Retrival},
      author = {Mikaela Angelina Uy and Jingwei Huang and Minhyuk Sung and Tolga Birdal and Leonidas Guibas},
      booktitle = {European Conference on Computer Vision (ECCV)},
      year = {2020}
  }</code></pre>    			
		</div>
		
        <!-- -->
        <br> 
        
  <div class="section">
      <h5>Acknowledgements</h5>            
      <p>
      This work is supported by a Google AR/VR University Research
      Award, a Vannevar Bush Faculty Fellowship, a grant from the Stanford SAIL Toyota
      Research Center, and gifts from the Adobe Corporation and the Dassault Foundation.
			</p>
  </div>
  </div>

    <script type="text/javascript" src="../js/jquery.min.js"></script>
    <script type="text/javascript" src="../js/footable.min.js"></script>

    <script type="text/javascript">
      jQuery(function($){
          $('.table').footable();
      });
    </script>

    <!-- End Document
         –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  </body>
</html>
